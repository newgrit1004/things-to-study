## Table of Contents

- [추천시스템의 이해](#1)
- [컨텐츠 기반 추천](#2)
- [협업 필터링](#3)
- [평가 함수](#4)



## #1
### 추천시스템의 이해
* 추천시스템 개요
    * 추천시스템의 정의는 사용자(user)에게 상품(item)을 제안하는 소프트웨어 도구.
    추천시스템의 목표는 어떤 사용자에게 어떤 상품을 어떠한 방법을 통해 추천할 것인지 결정하여 최종적으로 기업의 매출이나 플랫폼 사용 시간 등의 지표를 높이는 것.



* 기업에서의 추천시스템
    * 당근마켓
        * 다른 사람들이 <b>같이 본 상품</b> 추천.("이 상품과 함께 봤어요" 카테고리)
    * 카카오 (브런치)
        * 해당 글과 <b>유사한 글</b>을 추천.


* 추천시스템 용어
    * implicit feedback
        * 사용자가 상품을 구매했지만, 사용자가 상품 구매에 대한 만족 여부를 알 수 없는 데이터를 의미.(e.g. 대부분의 데이터)
    * explicit feedback
        * 사용자가 상품을 구매한 뒤, 상품 구매에 대한 만족 여부가 포함된 데이터를 의미.(e.g. 영화 평점 데이터)


* 과거의 추천시스템
    * 파레토의 법칙
        * 매출의 80%는 20%의 핵심 고객을 통해 나온다.
    * 롱테일 법칙
        * 인터넷의 발전 덕분에 하위 80%가 상위 20%의 가치보다 커졌다.
    * 연관 분석(Association Analysis)
        * 상품과 상품 사이의 연관을 찾아내는 알고리즘.
        * 연관의 정의
            * 얼마나 같이 구매가 되는가?
            * A 아이템을 구매하는 사람이(조건) B아이템을 구매하는가?
        * 평가 지표
            * 지지도(support) : support(A) = P(A,B)
                * A와 B가 동시에 포함된 거래/전체 거래수.
            * 향상도(lift) : lift(A->B) = P(A,B)/P(A)*P(B)
                * 두 사건이 동시에 얼마나 발생하는지 비율, 독립성을 측정.
            * 신뢰도(confidence) : confidence(A->B) = P(A,B)/P(A)
                * 상품 A를 구매했을 때, 상품 B까지 같이 구매할 확률.
            * 주로 지지도와 신뢰도가 높은 규칙을 선정.

        * 규칙 생성 방식
            * 전체 규칙 탐색 = nCr(r=0~n) = 2^(n)-1
            * A priori 알고리즘
                * 특징
                    * 아이템셋의 증가를 줄이기 위한 알고리즘.
                    * {2, 3}의 지지도 > {0, 2, 3}의 지지도.
                * 알고리즘
                    * 1. k개의 item을 가지고 단일 항목 집단을 생성한다.
                    * 2. 단일 항목 집단에서 사전에 정의한 최소 지지도(support) 이상의 항목만 선택한다.
                    * 3. 2에서 선택된 항목만을 대상으로 2개 항목집단 생성한다.
                    * 4. 2개 항목 집단에서 최소 지지도 또는 신뢰도 이상의 항목만 선택한다.
                    * 5. k개의 k-item frequent set을 생성할 때까지 반복한다.
                * 장점
                    * 원리가 간단하여 알고리즘 사용자가 쉽게 의미 해석이 가능함
                    * 유의한 연관성을 갖는 구매패턴 찾는 것이 가능
                * 단점
                    * 데이터가 많은 경우 연산량이 많아 속도가 느림
                * 라이브러리
                    * mlxtend


            * FP-growth 알고리즘
                * 특징
                    * A priori의 속도 측면의 단점을 FP Tree 구조를 사용하여 개선한 알고리즘.
                * 알고리즘
                    * 1. 모든 거래를 확인하여 각 아이템별 최소 지지도 이상의 아이템만 선택하고, 최소 지지도 미만의 아이템은 거래에서 삭제한다.
                    * 2. 모든 거래에서 거래별로 지지도가 높은 아이템 순서대로 순서를 내림차순으로 정렬한다.
                    * 3. 모든 거래에 대해서 새로운 아이템이 나올 경우 부모 노드로부터 시작하고, 그렇지 않은 경우 기존노드에서 확장하여 아이템 빈도 수를 더해준다.
                    4. 모든 거래를 반영한 FP-Tree가 생성된 뒤, 지지도가 낮은 아이템 순서부터 시작해서, 조건부 패턴을 생성한다.
                    5. 모든 아이템에 대해서 조건부 패턴 생성을 반복한다.
                * 장점
                    * A priori 알고리즘보다 빠르며 2번의 전체 탐색만 필요함.
                * 단점
                    * 대용량 데이터셋에 대해 메모리를 효율적으로 사용하지 않음.
                        * 지지도 계산이 FP-Tree 생성 뒤에 가능함.
                * 라이브러리
                    * mlxtend


## #2
### 컨텐츠 기반 추천
* 컨텐츠 기반 모델
    * 정의
        * 사용자가 이전에 구매한 상품 중에 선호하는 상품들과 유사한 상품을 추천해주는 방법.
    * 방법
        * 아이템을 벡터 형태로 표현하여 표현.
        * 예
            * 텍스트 : BERT, Word2Vec, TF-IDF
            * 이미지 : CNN 등
        * 벡터간의 유사도를 계산.
    * 장점
        * 협업필터링은 다른 사용자들의 평점이 필요하지만, 자신의 평점만으로 추천시스템 만들 수 있음.
        * item의 feature을 통해서 추천하기 때문에, 추천 이유를 설명하기 좋음
        * <b> cold start(e.g. 처음 들어온 사용자, 처음 개봉한 영화)의 케이스에 대해서도 추천이 가능함.</b>
    * 단점
        * 추천시스템의 성능이 item의 feature의 성능에 기반할 수 있음. 따라서 domain knowledge가 필요할 수 있음.
        * 기존 item과 유사한 item만 추천하므로 새로운 장르의 추천이 어려움.
        * 새로운 사용자에 대한 충분한 평점이 쌓이기 전에는 추천하기 힘듬.



* 유사도 함수
    * 유클리디안 유사도
        * 정의
            * 문서 간의 유사도를 계산.
            * 각 문서는 단어가 나타난 횟수로 표현됨.(e.g. doc1= {'과일이':0, '맛있다':2 })
        * formula
            * 1/(유클리디안 거리 + 1e-05)
        * 장점
            * 계산하기 쉬움.
        * 단점
            * p와 q의 분포 또는 범위가 다른 경우.
    * 코사인 유사도
        * 정의
            *
        * formula
            *
        * 장점
            * 벡터의 크기가 중요하지 않은 경우에 사용.
                * 문서 내에서의 단어 빈도수 : 문서들의 길이가 다르더라도, 문서 내에서의 비율을 확인하므로 괜찮음.
        * 단점
            * 벡터의 크기가 중요한 경우 잘 작동하지 않음.
    * 피어슨 유사도
        * 정의
            * #TODO
        * formula
            * #TODO

    * 자카드 유사도
        * 정의
            * 두 집합의 교집합의 크기/두 집합의 합집합의 크기.
    * Divergence 유사도(#TODO)
    * Dice 유사도(#TODO)
    * sorensen 유사도(#TODO)

    * 서로 다른 유사도를 조합하는 방법?
        * 각 유사도별로 추천시스템을 구축한 다음, 결과들을 조합해서 최종 추천을 함.
        * 각 유사도별을 가중치를 줘서 더한 다음에 그걸로 새로운 유사도를 정의한 다음 추천시스템을 구축함.
    * 도메인별 유사도
        * 어떤 아이템에 대한 추천시스템이냐에 따라 유사도가 크게 다르므로 도메인별 유사도 특징을 알아야함.


* TF-IDF 모델
    * 정의
        * 특정 문서 내에서 특정 단어가 얼마나 자주 등장하는지를 의미하는 단어 빈도(TF)와 전체 문서에서 특정 단어가 얼마나 자주 등장하는지를 의미하는 역문서 빈도(DF)를 통해서, 다른 문서에서는 등장하지 않지만 특정 문서에서만 자주 등장하는 단어를 찾아 문서 내 단어 가중치를 계산하는 방법.
    * 용어
        * TF(d,t)
            * 특정 문서 d에서 특정 단어 t의 등장 횟수.
        * DF(t)
            * 특정 단어 t가 등장한 문서의 수.
        * IDF(d,t)
            * idf(d,t) = log(n/(1+df(t)))
        * TF-IDF(d,t)
            * TF-IDF(d,t) = TF(d,t) * IDF(d,t)
    * 사용 이유
        * Counter Vectorizer(TF까지의 과정)라는 방법으로 빈도수가 많이 나오는 단어들에 대해 중요도를 높여줄 수 있다. 하지만 이럴 경우 조사/관사처럼 의미가 없는 단어들의 중요도가 높아지는 문제점이 발생할 수 있다. 따라서 이러한 단어들에 대해서 패널티를 줘서 중요한 단어들을 잡아내는 방법이 TF-IDF 방법이다.
    * 장점
        * 직관적 해석 가능.
    * 단점
        * 대규모 말뭉치를 다룰 때 메모리 문제 발생
            * 높은 차원
            * 매우 sparse한 데이터
    * 라이브러리
        * scikit-learn
            * CountVectorizer
            * TFidfVectorizer


* Word2Vec
    * 정의
        * 원핫인코딩 벡터 형태의 sparse matrix가 가지는 단점을 해소하고자 제안된 방법.
        * "비슷한 위치에 등장하는 단어들은 비슷한 의미를 가진다"라는 가정을 통해 학습.
        * 단어간 유사도를 반영하여 단어를 벡터로 바꿔주는 임베딩 방법론.
        * 추천시스템에서는 단어를 구매 상품으로 바꾸어 구매한 패턴에 word2vec을 적용하여 비슷한 상품을 찾을 수 있음.

    * 기존 통계기반 방법 단점
        * 대규모 말뭉치를 다룰 때, sparse한 데이터를 다루므로 메모리상 문제 발생.
        * 한번에 학습 데이터 전체를 진행함.
            * 큰 작업을 처리하기 어려움.
    * CBOW
        * 주변에 있는 단어를 이용하여 중간에 있는 단어들을 예측하는 방법.
    * Skip-Gram
        * 중간에 있는 단어로 주변 단어를 예측하는 방법.
        * CBOW보다 성능이 좋음.



## #3
### 협업 필터링
* KNN
    *


* SGD
    *


* ALS
    *



# References
- [[토크ON세미나] 추천시스템 분석 입문하기](https://www.youtube.com/watch?v=43gb7WK56Sk&list=PL9mhQYIlKEhdkOVTZWJJIy8rv6rQaZNNc&index=1)




